{"paragraphs":[{"config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1483712102505_909254767","id":"20170106-231502_1877785852","dateCreated":"2017-01-06T23:15:02+0900","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:1573","text":"/*\r\n\tThis code is intended to be run in the Scala shell. \r\n\tLaunch the Scala Spark shell by running ./bin/spark-shell from the Spark directory.\r\n\tYou can enter each line in the shell and see the result immediately.\r\n\tThe expected output in the Spark console is presented as commented lines following the\r\n\trelevant code\r\n\r\n\tThe Scala shell creates a SparkContex variable available to us as 'sc'\r\n\r\n\tEnsure you you start your Spark shell with enough memory:\r\n\t\t./bin/spark-shell --driver-memory 4g \r\n*/\r\n\r\n/* Replace 'PATH' with the path to the 20 Newsgroups Data */\r\nval path = \"D:\\\\Project\\\\Spark\\\\Machine-Learning-with-Spark\\\\Data\\\\20news-bydate\"\r\nval rdd = sc.wholeTextFiles(path + \"\\\\20news-bydate-train\\\\*\")\r\n// count the number of records in the dataset\r\nprintln(rdd.count)","dateUpdated":"2017-01-07T00:14:06+0900","dateFinished":"2017-01-07T00:27:30+0900","dateStarted":"2017-01-07T00:14:06+0900","result":{"code":"SUCCESS","type":"TEXT","msg":"11314\r\n\r\n\npath: String = D:\\Project\\Spark\\Machine-Learning-with-Spark\\Data\\20news-bydate\r\nrdd: org.apache.spark.rdd.RDD[(String, String)] = D:\\Project\\Spark\\Machine-Learning-with-Spark\\Data\\20news-bydate\\20news-bydate-train\\* MapPartitionsRDD[917] at wholeTextFiles at <console>:60\n"},"focus":true},{"config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1483712383482_2063115074","id":"20170106-231943_616089546","dateCreated":"2017-01-06T23:19:43+0900","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:1647","dateUpdated":"2017-01-07T00:28:52+0900","dateFinished":"2017-01-07T00:31:02+0900","dateStarted":"2017-01-07T00:28:52+0900","result":{"code":"SUCCESS","type":"TEXT","msg":"\nnewsgroups: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[918] at map at <console>:46\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\ncountByGroup: String =\r\n(rec.sport.hockey,600)\r\n(soc.religion.christian,599)\r\n(rec.motorcycles,598)\r\n(rec.sport.baseball,597)\r\n(sci.crypt,595)\r\n(rec.autos,594)\r\n(sci.med,594)\r\n(comp.windows.x,593)\r\n(sci.space,593)\r\n(sci.electronics,591)\r\n(comp.os.ms-windows.misc,591)\r\n(comp.sys.ibm.pc.hardware,590)\r\n(misc.forsale,585)\r\n(comp.graphics,584)\r\n(comp.sys.mac.hardware,578)\r\n(talk.politics.mideast,564)\r\n(talk.politics.guns,546)\r\n(alt.atheism,480)\r\n(talk.politics.misc,465)\r\n(talk.religion.misc,377)\n(rec.sport.hockey,600)\n(soc.religion.christian,599)\n(rec.motorcycles,598)\n(rec.sport.baseball,597)\n(sci.crypt,595)\n(rec.autos,594)\n(sci.med,594)\n(comp.windows.x,593)\n(sci.space,593)\n(sci.electronics,591)\n(comp.os.ms-windows.misc,591)\n(comp.sys.ibm.pc.hardware,590)\n(misc.forsale,585)\n(comp.graphics,584)\n(comp.sys.mac.hardware,578)\n(talk.politics.mideast,564)\n(talk.politics.guns,546)\n(alt.atheism,480)\n(talk.politics.misc,465)\n(talk.religion.misc,377)\r\n"},"text":"val newsgroups = rdd.map { case (file, text) => file.split(\"/\").takeRight(2).head }\r\nval countByGroup = newsgroups.map(n => (n, 1)).reduceByKey(_ + _).collect.sortBy(-_._2).mkString(\"\\n\")\r\nprintln(countByGroup)"},{"config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1483712386376_-1881730723","id":"20170106-231946_218145730","dateCreated":"2017-01-06T23:19:46+0900","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:1717","dateUpdated":"2017-01-07T00:31:35+0900","dateFinished":"2017-01-07T00:33:43+0900","dateStarted":"2017-01-07T00:31:35+0900","result":{"code":"SUCCESS","type":"TEXT","msg":"\ntext: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[921] at map at <console>:47\n\nwhiteSpaceSplit: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[922] at flatMap at <console>:48\n402978\r\n"},"text":"// Tokenizing the text data\r\nval text = rdd.map { case (file, text) => text }\r\nval whiteSpaceSplit = text.flatMap(t => t.split(\" \").map(_.toLowerCase))\r\nprintln(whiteSpaceSplit.distinct.count)"},{"config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1483712388261_-1129546623","id":"20170106-231948_1081619374","dateCreated":"2017-01-06T23:19:48+0900","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:1787","dateUpdated":"2017-01-07T00:36:35+0900","dateFinished":"2017-01-07T00:36:36+0900","dateStarted":"2017-01-07T00:36:35+0900","result":{"code":"SUCCESS","type":"TEXT","msg":"addresses,,--,atheism,,cambridge.,<19930301143317@mantis.co.uk>\nlines:,290\n\narchive-name:,december,1.0\n\n,,,,,,,,,,,of,,,,,,,foundation\n\ndarwin,assorted,atheist,are\navailable,to:,(608),the,\"darwin,fish\".,it's,it's,symbol,,symbol,,like,like,stick,on,cars,,but,but,and,the,is,in,the,the,the,#4,,hollywood,\n,,san,darwin,gold,for,net,who,lynn,directly,,the\nprice,the\nprice,fish.\n\namerican,books,critiques,critiques,the,bible,,of\nbiblical,contradictions,,contradictions,,,and,american,0-910309-26-4,,edition,,atrocities,,contains,foote:,bible\ncontradicts,aap.,king,american,,(512),,books\n\nsell,haught's,horrors\",(see,,york,york,newer,is:\nprometheus,is:\nprometheus,14228-2197.\n\nafrican-americans\r\n"},"text":"// inspect a look at a sample of tokens - note we set the random seed to get the same results each time\r\nprintln(whiteSpaceSplit.sample(true, 0.3, 42).take(100).mkString(\",\"))"},{"config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1483712390738_1694925701","id":"20170106-231950_92802852","dateCreated":"2017-01-06T23:19:50+0900","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:1857","text":"// split text on any non-word tokens\r\nval nonWordSplit = text.flatMap(t => t.split(\"\"\"\\W+\"\"\").map(_.toLowerCase))\r\nprintln(nonWordSplit.distinct.count)","dateUpdated":"2017-01-07T00:36:54+0900","dateFinished":"2017-01-07T00:39:05+0900","dateStarted":"2017-01-07T00:36:54+0900","result":{"code":"SUCCESS","type":"TEXT","msg":"\nnonWordSplit: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[927] at flatMap at <console>:49\n130126\r\n"}},{"config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1483712680393_1058164627","id":"20170106-232440_2065043740","dateCreated":"2017-01-06T23:24:40+0900","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:1927","dateUpdated":"2017-01-07T00:36:58+0900","dateFinished":"2017-01-07T00:41:22+0900","dateStarted":"2017-01-07T00:36:58+0900","result":{"code":"SUCCESS","type":"TEXT","msg":"wuair,schwabam,42b,125215,6j,he3,1pqd9hinnbmi,neurologists,jxicaijp,dwi,749,steaminess,dangers,qsins,instantaneous,391k,typeset,typeset,bippy,hollombe,mswin,diccon,4h0kj76,borg,g85,spe,kocharian,6097,1tbs,xs9,3zur,unaskable,9mf,cj1v,bowdoin,bowdoin,inre,inre,deadweight,deadweight,deterministic,createwindow,rockefeller,kjznkh,kjznkh,classifieds,ray_bourque,anachronistic,cherylm,005117,005117,005117,interfere,makewindow,mtearle,barking,ww2,vcrs,widmann,monger,projector,jdecarlo,warms,triangulate,triangulate,recieves,g45,rint69,rint69,herod,1496,libpackagexcl,6w8rg,6w8rg,00ecgillespie,phoniest,funded,canonical,ehs,birds,dxb132,xtappcontext,0iy4bn,lamers,023843,inconsitancies,isdres,trn,xa_rgb_default_map,dm9,rchzd2_8d,mtagm,walters,r1865,9gtf,9gtf,lfu1i9b,tyrell,tyrell,rvik\r\n"},"text":"// inspect a look at a sample of tokens\r\nprintln(nonWordSplit.distinct.sample(true, 0.3, 42).take(100).mkString(\",\"))"},{"config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1483712688109_808477915","id":"20170106-232448_57570701","dateCreated":"2017-01-06T23:24:48+0900","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:2137","text":"// filter out numbers\r\nval regex = \"\"\"[^0-9]*\"\"\".r\r\nval filterNumbers = nonWordSplit.filter(token => regex.pattern.matcher(token).matches)\r\nprintln(filterNumbers.distinct.count)","dateUpdated":"2017-01-07T00:42:01+0900","dateFinished":"2017-01-07T00:44:15+0900","dateStarted":"2017-01-07T00:42:01+0900","result":{"code":"SUCCESS","type":"TEXT","msg":"\nregex: scala.util.matching.Regex = [^0-9]*\n\nfilterNumbers: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[935] at filter at <console>:52\n84912\r\n"}},{"config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1483712685480_244051278","id":"20170106-232445_1621012084","dateCreated":"2017-01-06T23:24:45+0900","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:2067","text":"println(filterNumbers.distinct.sample(true, 0.3, 42).take(100).mkString(\",\"))","dateUpdated":"2017-01-07T00:44:48+0900","dateFinished":"2017-01-07T00:47:02+0900","dateStarted":"2017-01-07T00:44:48+0900","result":{"code":"SUCCESS","type":"TEXT","msg":"ntuvax,dpsi,singen,leymarie,_congressional,fowl,rlhzrlhz,afterward,ignore,hcq,beleive,goofed,arax,dfuller,nondiscriminatory,steaminess,urtfi,urtfi,za_,tiems,bellevue,typeset,armegedon,gunning,croissant,yearsley,dolphin,tic,worshippers,theoreticians,siumv,arresed,borg,sunprops,sask,sask,subcircuits,subcircuits,uninjured,uninjured,internship,pws,keysym,vfj,vfj,connecters,spe,octopi,bhjn,winsor,winsor,winsor,yan,astonished,miserable,eng,subtleties,createwindow,silvers,explorers,antisemites,classifieds,ray_bourque,inviting,inviting,apply,cfsmo,holdren,holdren,mishandles,feszcm,rootx,scramblers,scramblers,nkm,hfd,makewindow,formac,exhausting,responsbible,paradijs,fuenfzig,hindenburg,trial,tact,fahrenheit,projector,jdecarlo,ndallen,recoend,ffbv,bracing,wy,herod,sonunda,sonunda,depicted,iauc,iauc,floor\r\n"}},{"config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1483712736173_-1614023754","id":"20170106-232536_1051325741","dateCreated":"2017-01-06T23:25:36+0900","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:2347","text":"// examine potential stopwords\r\nval tokenCounts = filterNumbers.map(t => (t, 1)).reduceByKey(_ + _)\r\nval oreringDesc = Ordering.by[(String, Int), Int](_._2)\r\nprintln(tokenCounts.top(20)(oreringDesc).mkString(\"\\n\"))","dateUpdated":"2017-01-07T00:48:52+0900","dateFinished":"2017-01-07T00:51:03+0900","dateStarted":"2017-01-07T00:48:52+0900","result":{"code":"SUCCESS","type":"TEXT","msg":"\ntokenCounts: org.apache.spark.rdd.RDD[(String, Int)] = ShuffledRDD[944] at reduceByKey at <console>:55\n\noreringDesc: scala.math.Ordering[(String, Int)] = scala.math.Ordering$$anon$9@1b5f8beb\n(the,146532)\n(to,75064)\n(of,69034)\n(a,64195)\n(ax,62406)\n(and,57957)\n(i,53036)\n(in,49402)\n(is,43480)\n(that,39264)\n(it,33638)\n(for,28600)\n(you,26682)\n(from,22670)\n(s,22337)\n(edu,21321)\n(on,20493)\n(this,20121)\n(be,19285)\n(t,18728)\r\n"}},{"config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1483712785863_-221389266","id":"20170106-232625_938289184","dateCreated":"2017-01-06T23:26:25+0900","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:2557","text":"// filter out stopwords\r\nval stopwords = Set(\r\n\t\"the\",\"a\",\"an\",\"of\",\"or\",\"in\",\"for\",\"by\",\"on\",\"but\", \"is\", \"not\", \"with\", \"as\", \"was\", \"if\",\r\n\t\"they\", \"are\", \"this\", \"and\", \"it\", \"have\", \"from\", \"at\", \"my\", \"be\", \"that\", \"to\"\r\n)\r\nval tokenCountsFilteredStopwords = tokenCounts.filter { case (k, v) => !stopwords.contains(k) }\r\nprintln(tokenCountsFilteredStopwords.top(20)(oreringDesc).mkString(\"\\n\"))","dateUpdated":"2017-01-07T00:52:21+0900","dateFinished":"2017-01-07T00:52:22+0900","dateStarted":"2017-01-07T00:52:21+0900","result":{"code":"SUCCESS","type":"TEXT","msg":"\nstopwords: scala.collection.immutable.Set[String] = Set(for, this, in, have, are, is, but, if, it, a, as, or, they, that, to, was, at, on, my, by, not, with, from, an, be, of, and, the)\n\ntokenCountsFilteredStopwords: org.apache.spark.rdd.RDD[(String, Int)] = MapPartitionsRDD[946] at filter at <console>:58\n(ax,62406)\n(i,53036)\n(you,26682)\n(s,22337)\n(edu,21321)\n(t,18728)\n(m,12756)\n(subject,12264)\n(com,12133)\n(lines,11835)\n(can,11355)\n(organization,11233)\n(re,10534)\n(what,9861)\n(there,9689)\n(x,9332)\n(all,9310)\n(will,9279)\n(we,9227)\n(one,9008)\r\n"}},{"config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1483712784941_-163676931","id":"20170106-232624_573143905","dateCreated":"2017-01-06T23:26:24+0900","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:2487","text":"// filter out tokens less than 2 characters\r\nval tokenCountsFilteredSize = tokenCountsFilteredStopwords.filter { case (k, v) => k.size >= 2 }\r\nprintln(tokenCountsFilteredSize.top(20)(oreringDesc).mkString(\"\\n\"))","dateUpdated":"2017-01-07T00:53:15+0900","dateFinished":"2017-01-07T00:53:16+0900","dateStarted":"2017-01-07T00:53:15+0900","result":{"code":"SUCCESS","type":"TEXT","msg":"\ntokenCountsFilteredSize: org.apache.spark.rdd.RDD[(String, Int)] = MapPartitionsRDD[948] at filter at <console>:61\n(ax,62406)\n(you,26682)\n(edu,21321)\n(subject,12264)\n(com,12133)\n(lines,11835)\n(can,11355)\n(organization,11233)\n(re,10534)\n(what,9861)\n(there,9689)\n(all,9310)\n(will,9279)\n(we,9227)\n(one,9008)\n(would,8905)\n(do,8674)\n(he,8441)\n(about,8336)\n(writes,7844)\r\n"}},{"config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1483712783878_-1329081350","id":"20170106-232623_1933564744","dateCreated":"2017-01-06T23:26:23+0900","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:2417","text":"// examine tokens with least occurrence\r\nval oreringAsc = Ordering.by[(String, Int), Int](-_._2)\r\nprintln(tokenCountsFilteredSize.top(20)(oreringAsc).mkString(\"\\n\"))","dateUpdated":"2017-01-07T00:53:24+0900","dateFinished":"2017-01-07T00:53:25+0900","dateStarted":"2017-01-07T00:53:24+0900","result":{"code":"SUCCESS","type":"TEXT","msg":"\noreringAsc: scala.math.Ordering[(String, Int)] = scala.math.Ordering$$anon$9@341be08e\n(altina,1)\n(bluffing,1)\n(preload,1)\n(lennips,1)\n(actu,1)\n(vno,1)\n(wbp,1)\n(donnalyn,1)\n(ydag,1)\n(mirosoft,1)\n(jjjjrw,1)\n(harger,1)\n(conts,1)\n(bankruptcies,1)\n(uncompression,1)\n(d_nibby,1)\n(bunuel,1)\n(odf,1)\n(swith,1)\n(pacified,1)\r\n"}},{"config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1483712735364_-1499753331","id":"20170106-232535_1847710641","dateCreated":"2017-01-06T23:25:35+0900","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:2277","text":"// filter out rare tokens with total occurence < 2\r\nval rareTokens = tokenCounts.filter{ case (k, v) => v < 2 }.map { case (k, v) => k }.collect.toSet\r\nval tokenCountsFilteredAll = tokenCountsFilteredSize.filter { case (k, v) => !rareTokens.contains(k) }\r\n\r\nprintln(tokenCountsFilteredAll.top(20)(oreringAsc).mkString(\"\\n\"))\r\nprintln(tokenCountsFilteredAll.count)","dateUpdated":"2017-01-07T00:55:31+0900","dateFinished":"2017-01-07T00:55:33+0900","dateStarted":"2017-01-07T00:55:31+0900","result":{"code":"SUCCESS","type":"TEXT","msg":"rareTokens: scala.collection.immutable.Set[String] = Set(kherron, nzo, dredd, kaiserstrasse, additivity, holsman, xbench, synchronicity, t_vb, soner, ipn, vaxsyn, rmad, healings, biopsied, kettler, boxers, rljry, brownmiller, compatabilty, blacklight, lederle, wimmer, radionic, books___________________, derided, trenyg, sputtering, gogles, tcy, wakaluk, zrcj, zwakke, emplacements, telaviv, vov, striato, jena, shorci, twosey, ytkim, grpxjq, kalem, medizinische, bjxy, pipex, additonally, ellet, evenzo, blowtisserie, dyi, xtva, michels, bastyr, norht, thrashed, mqo, mise, chalkboard, pgc, clough, internist, plugin, gowan, scathing, hember, ripems, mgzg, poli, vyep, numner, ybwuwlntm, delray, oversamplings, cpowell, absorbs, unknow, peavax, seamans, _zszcmti, pubbrew, _miraculin_, cellerato...\ntokenCountsFilteredAll: org.apache.spark.rdd.RDD[(String, Int)] = MapPartitionsRDD[957] at filter at <console>:64\n(sina,2)\n(akachhy,2)\n(mvd,2)\n(sarkis,2)\n(wendel_clark,2)\n(relieves,2)\n(purposeful,2)\n(hizbolah,2)\n(wout,2)\n(uneven,2)\n(senna,2)\n(subdivided,2)\n(bushy,2)\n(feagans,2)\n(coretest,2)\n(oww,2)\n(historicity,2)\n(mmg,2)\n(margitan,2)\n(defiance,2)\r\n51801\r\n"}},{"config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1483712844472_-1016387763","id":"20170106-232724_1590724642","dateCreated":"2017-01-06T23:27:24+0900","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:2627","text":"// create a function to tokenize each document\r\ndef tokenize(line: String): Seq[String] = {\r\n\tline.split(\"\"\"\\W+\"\"\")\r\n\t\t.map(_.toLowerCase)\r\n\t\t.filter(token => regex.pattern.matcher(token).matches)\r\n\t\t.filterNot(token => stopwords.contains(token))\r\n\t\t.filterNot(token => rareTokens.contains(token))\r\n\t\t.filter(token => token.size >= 2)\r\n\t\t.toSeq\r\n}\r\n\r\n// check that our tokenizer achieves the same result as all the steps above\r\nprintln(text.flatMap(doc => tokenize(doc)).distinct.count)","dateUpdated":"2017-01-07T00:55:56+0900","dateFinished":"2017-01-07T00:58:13+0900","dateStarted":"2017-01-07T00:55:56+0900","result":{"code":"SUCCESS","type":"TEXT","msg":"\ntokenize: (line: String)Seq[String]\n51801\r\n"}},{"config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1483712734079_1826031486","id":"20170106-232534_1324554261","dateCreated":"2017-01-06T23:25:34+0900","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:2207","text":"// tokenize each document\r\nval tokens = text.map(doc => tokenize(doc))\r\nprintln(tokens.first.take(20))","dateUpdated":"2017-01-07T00:58:22+0900","dateFinished":"2017-01-07T00:58:23+0900","dateStarted":"2017-01-07T00:58:22+0900","result":{"code":"SUCCESS","type":"TEXT","msg":"\ntokens: org.apache.spark.rdd.RDD[Seq[String]] = MapPartitionsRDD[963] at map at <console>:63\nWrappedArray(mathew, mathew, mantis, co, uk, subject, alt, atheism, faq, atheist, resources, summary, books, addresses, music, anything, related, atheism, keywords, faq)\r\n"}},{"config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1483712882022_-1347980018","id":"20170106-232802_1654161614","dateCreated":"2017-01-06T23:28:02+0900","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:2907","text":"// === train TF-IDF model === //\r\nimport org.apache.spark.mllib.linalg.{ SparseVector => SV }\r\nimport org.apache.spark.mllib.feature.HashingTF\r\nimport org.apache.spark.mllib.feature.IDF\r\n\r\n// set the dimensionality of TF-IDF vectors to 2^18\r\nval dim = math.pow(2, 18).toInt\r\nval hashingTF = new HashingTF(dim)\r\n\r\nval tf = hashingTF.transform(tokens)\r\n// cache data in memory\r\ntf.cache\r\nval v = tf.first.asInstanceOf[SV]\r\n\r\nprintln(v.size)\r\nprintln(v.values.size)\r\nprintln(v.values.take(10).toSeq)\r\nprintln(v.indices.take(10).toSeq)","dateUpdated":"2017-01-07T01:01:01+0900","dateFinished":"2017-01-07T01:00:40+0900","dateStarted":"2017-01-07T00:58:43+0900","result":{"code":"SUCCESS","type":"TEXT","msg":"\nimport org.apache.spark.mllib.linalg.{SparseVector=>SV}\n\nimport org.apache.spark.mllib.feature.HashingTF\n\nimport org.apache.spark.mllib.feature.IDF\n\ndim: Int = 262144\n\nhashingTF: org.apache.spark.mllib.feature.HashingTF = org.apache.spark.mllib.feature.HashingTF@75b3e07a\n\ntf: org.apache.spark.rdd.RDD[org.apache.spark.mllib.linalg.Vector] = MapPartitionsRDD[964] at map at HashingTF.scala:120\n\nres127: tf.type = MapPartitionsRDD[964] at map at HashingTF.scala:120\nv: org.apache.spark.mllib.linalg.SparseVector = (262144,[15,1469,2276,2329,2366,2410,2548,2710,2992,3834,4200,5381,5519,5595,5795,6183,6758,8976,9014,9592,9988,10286,11275,12336,12433,12781,12888,13142,13185,13471,13522,13957,13995,14949,15207,17011,17964,18322,18471,18638,19208,19566,19978,20296,20421,21471,21872,22206,23304,23574,23875,24031,24145,24303,24626,24856,24918,24980,25000,25217,25273,25596,25859,25964,26264,26445,28910,29766,29945,30329,30545,30675,31313,32258,32329,33053,33174,33226,33389,33437,33532,34116,34183,34343,34616,35050,35119,35535,36073,36278,36449,36495,37080,37735,38064,38068,38194,38420,39772,39964,40888,41229,41262,41282,41520,42230,42565,43193,43384,44587,44635,44836,45038,45145,45522,45622,46080,46949,47372,48172,48383,48521,48607,48935,49270,50101,50303,5...262144\r\n706\r\nWrappedArray(1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 3.0, 4.0)\r\nWrappedArray(15, 1469, 2276, 2329, 2366, 2410, 2548, 2710, 2992, 3834)\r\n"}},{"config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1483713063835_-361242464","id":"20170106-233103_936057437","dateCreated":"2017-01-06T23:31:03+0900","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:3187","text":"val idf = new IDF().fit(tf)\r\nval tfidf = idf.transform(tf)\t\r\nval v2 = tfidf.first.asInstanceOf[SV]\r\n\r\nprintln(v2.values.size)\r\nprintln(v2.values.take(10).toSeq)\r\nprintln(v2.indices.take(10).toSeq)","dateUpdated":"2017-01-07T01:02:16+0900","dateFinished":"2017-01-07T01:03:26+0900","dateStarted":"2017-01-07T01:02:16+0900","result":{"code":"SUCCESS","type":"TEXT","msg":"\nidf: org.apache.spark.mllib.feature.IDFModel = org.apache.spark.mllib.feature.IDFModel@71651462\n\ntfidf: org.apache.spark.rdd.RDD[org.apache.spark.mllib.linalg.Vector] = MapPartitionsRDD[966] at mapPartitions at IDF.scala:178\nv2: org.apache.spark.mllib.linalg.SparseVector = (262144,[15,1469,2276,2329,2366,2410,2548,2710,2992,3834,4200,5381,5519,5595,5795,6183,6758,8976,9014,9592,9988,10286,11275,12336,12433,12781,12888,13142,13185,13471,13522,13957,13995,14949,15207,17011,17964,18322,18471,18638,19208,19566,19978,20296,20421,21471,21872,22206,23304,23574,23875,24031,24145,24303,24626,24856,24918,24980,25000,25217,25273,25596,25859,25964,26264,26445,28910,29766,29945,30329,30545,30675,31313,32258,32329,33053,33174,33226,33389,33437,33532,34116,34183,34343,34616,35050,35119,35535,36073,36278,36449,36495,37080,37735,38064,38068,38194,38420,39772,39964,40888,41229,41262,41282,41520,42230,42565,43193,43384,44587,44635,44836,45038,45145,45522,45622,46080,46949,47372,48172,48383,48521,48607,48935,49270,50101,50303,...706\r\nWrappedArray(3.291251724385256, 6.3894455789011975, 6.694827228452379, 5.421861552639491, 4.964436705600616, 3.746635899667388, 8.979394943218093, 3.9448128282511368, 12.032623736787688, 14.839468207521197)\r\nWrappedArray(15, 1469, 2276, 2329, 2366, 2410, 2548, 2710, 2992, 3834)\r\n"}},{"config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1483713062299_-1346199649","id":"20170106-233102_1919302090","dateCreated":"2017-01-06T23:31:02+0900","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:3117","text":"// min and max tf-idf scores\r\nval minMaxVals = tfidf.map { v => \r\n\tval sv = v.asInstanceOf[SV]\r\n\t(sv.values.min, sv.values.max) \r\n}\r\nval globalMinMax = minMaxVals.reduce { case ((min1, max1), (min2, max2)) => \r\n\t(math.min(min1, min2), math.max(max1, max2)) \r\n}\r\n\r\nprintln(globalMinMax)","dateUpdated":"2017-01-07T01:04:20+0900","dateFinished":"2017-01-07T01:04:21+0900","dateStarted":"2017-01-07T01:04:20+0900","result":{"code":"SUCCESS","type":"TEXT","msg":"\nminMaxVals: org.apache.spark.rdd.RDD[(Double, Double)] = MapPartitionsRDD[967] at map at <console>:80\n\nglobalMinMax: (Double, Double) = (0.0,66155.39470409753)\n(0.0,66155.39470409753)\r\n"}},{"config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1483713061203_-1023010572","id":"20170106-233101_1365894045","dateCreated":"2017-01-06T23:31:01+0900","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:3047","text":"// test out a few common words \r\nval common = sc.parallelize(Seq(Seq(\"you\", \"do\", \"we\")))\r\nval tfCommon = hashingTF.transform(common)\r\nval tfidfCommon = idf.transform(tfCommon)\r\nval commonVector = tfidfCommon.first.asInstanceOf[SV]\r\n\r\nprintln(commonVector.values.toSeq)","dateUpdated":"2017-01-07T01:04:43+0900","dateFinished":"2017-01-07T01:04:45+0900","dateStarted":"2017-01-07T01:04:43+0900","result":{"code":"SUCCESS","type":"TEXT","msg":"\ncommon: org.apache.spark.rdd.RDD[Seq[String]] = ParallelCollectionRDD[968] at parallelize at <console>:47\n\ntfCommon: org.apache.spark.rdd.RDD[org.apache.spark.mllib.linalg.Vector] = MapPartitionsRDD[969] at map at HashingTF.scala:120\n\ntfidfCommon: org.apache.spark.rdd.RDD[org.apache.spark.mllib.linalg.Vector] = MapPartitionsRDD[970] at mapPartitions at IDF.scala:178\n\ncommonVector: org.apache.spark.mllib.linalg.SparseVector = (262144,[37470,147489,252801],[0.9965359935704624,1.3348773448236835,0.5454436006630441])\nWrappedArray(0.9965359935704624, 1.3348773448236835, 0.5454436006630441)\r\n"}},{"config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1483713270525_-232612094","id":"20170106-233430_1886050686","dateCreated":"2017-01-06T23:34:30+0900","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:3467","text":"// test out a few uncommon words\r\nval uncommon = sc.parallelize(Seq(Seq(\"telescope\", \"legislation\", \"investment\")))\r\nval tfUncommon = hashingTF.transform(uncommon)\r\nval tfidfUncommon = idf.transform(tfUncommon)\r\nval uncommonVector = tfidfUncommon.first.asInstanceOf[SV]\r\n\r\nprintln(uncommonVector.values.toSeq)","dateUpdated":"2017-01-07T01:04:58+0900","dateFinished":"2017-01-07T01:05:00+0900","dateStarted":"2017-01-07T01:04:59+0900","result":{"code":"SUCCESS","type":"TEXT","msg":"\nuncommon: org.apache.spark.rdd.RDD[Seq[String]] = ParallelCollectionRDD[971] at parallelize at <console>:47\n\ntfUncommon: org.apache.spark.rdd.RDD[org.apache.spark.mllib.linalg.Vector] = MapPartitionsRDD[972] at map at HashingTF.scala:120\n\ntfidfUncommon: org.apache.spark.rdd.RDD[org.apache.spark.mllib.linalg.Vector] = MapPartitionsRDD[973] at mapPartitions at IDF.scala:178\n\nuncommonVector: org.apache.spark.mllib.linalg.SparseVector = (262144,[66704,129951,260003],[5.363592644515516,5.3265513728351666,5.442064259957011])\nWrappedArray(5.363592644515516, 5.3265513728351666, 5.442064259957011)\r\n"}},{"config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1483713267083_-1873950902","id":"20170106-233427_1400452168","dateCreated":"2017-01-06T23:34:27+0900","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:3397","text":"// === document similarity === //\r\nval hockeyText = rdd.filter { case (file, text) => file.contains(\"hockey\") }\r\n\r\n// note that the 'transform' method used below is the one which works on a single document \r\n// in the form of a Seq[String], rather than the version which works on an RDD of documents\r\nval hockeyTF = hockeyText.mapValues(doc => hashingTF.transform(tokenize(doc)))\r\nval hockeyTfIdf = idf.transform(hockeyTF.map(_._2))\r\n\r\n// compute cosine similarity using Breeze\r\nimport breeze.linalg._\r\n\r\nval hockey1 = hockeyTfIdf.sample(true, 0.1, 42).first.asInstanceOf[SV]\r\nval breeze1 = new SparseVector(hockey1.indices, hockey1.values, hockey1.size)\r\nval hockey2 = hockeyTfIdf.sample(true, 0.1, 43).first.asInstanceOf[SV]\r\nval breeze2 = new SparseVector(hockey2.indices, hockey2.values, hockey2.size)\r\nval cosineSim = breeze1.dot(breeze2) / (norm(breeze1) * norm(breeze2))\r\n\r\nprintln(cosineSim)","dateUpdated":"2017-01-07T01:05:32+0900","dateFinished":"2017-01-07T01:08:56+0900","dateStarted":"2017-01-07T01:05:32+0900","result":{"code":"SUCCESS","type":"TEXT","msg":"\nhockeyText: org.apache.spark.rdd.RDD[(String, String)] = MapPartitionsRDD[974] at filter at <console>:50\n\nhockeyTF: org.apache.spark.rdd.RDD[(String, org.apache.spark.mllib.linalg.Vector)] = MapPartitionsRDD[975] at mapValues at <console>:71\n\nhockeyTfIdf: org.apache.spark.rdd.RDD[org.apache.spark.mllib.linalg.Vector] = MapPartitionsRDD[977] at mapPartitions at IDF.scala:178\n\nimport breeze.linalg._\nhockey1: org.apache.spark.mllib.linalg.SparseVector = (262144,[14,1858,2316,2325,3168,3924,4594,6781,7336,7717,8449,8804,14219,15560,15664,23893,24977,24980,26083,26113,28622,28629,29945,34116,34234,40029,40198,40963,44923,48607,50134,51024,57414,58162,59733,60252,61971,62425,63082,65212,65531,66014,66869,66980,68620,68867,70527,73197,73660,75042,81566,82065,82495,86100,88359,90757,91137,91482,92854,93843,97171,99277,102299,102824,102935,103048,104948,105063,105664,108493,110004,110589,112802,113432,113764,118590,120739,124386,125133,125372,126768,126783,126831,128231,132270,132975,135560,138677,140390,140532,140784,141117,141946,145449,146255,146777,148240,150093,155521,160043,161061,162813,163197,166027,167200,167918,168044,168976,175541,175636,178286,179344,179490,180220,180535,18163...breeze1: breeze.linalg.SparseVector[Double] = SparseVector((14,5.8740072295578765), (1858,6.0016800478924335), (2316,18.114143076189926), (2325,3.123284481042985), (3168,4.759173579564255), (3924,3.2654589698235275), (4594,4.050680829329649), (6781,4.451082635481267), (7336,4.597686109673142), (7717,4.661055723605732), (8449,4.343451971288902), (8804,2.449397906024855), (14219,3.2224172185649596), (15560,6.500671214011422), (15664,1.8267434783400298), (23893,2.3849873357543254), (24977,4.209920578664379), (24980,1.3002261301814875), (26083,16.78864481935281), (26113,5.3265513728351666), (28622,5.966588728081164), (28629,5.8998973535824915), (29945,6.536168602682607), (34116,1.483001893257786), (34234,21.934947825430317), (40029,6.7689352006061005), (40198,4.845248188335498), (40963,4.29...hockey2: org.apache.spark.mllib.linalg.SparseVector = (262144,[513,1858,2316,2325,4594,5212,5381,6369,7617,9616,11065,11104,13396,14385,16426,18327,19208,20039,20509,20832,22552,23126,23893,24386,24980,25551,26044,26214,27544,28182,28402,28622,28885,29066,29238,29917,29945,30006,30988,31463,32390,32392,32976,33162,34116,34140,35758,35883,36073,36200,37251,37470,38765,40225,41704,42990,44923,45152,45190,45916,46053,46299,46505,47032,47309,47819,48482,48591,50034,50223,51044,53570,53718,54083,54961,55039,56683,57414,58132,58162,58227,59247,59544,59729,59853,60191,60294,60771,60967,61231,61625,61971,62713,63440,65212,65597,65844,66980,68727,68867,70028,70527,71222,73058,73660,74473,75398,75442,75967,76764,77492,78329,78628,80245,81566,82111,83756,84557,84837,86263,87052,87367,87478,88883,8...breeze2: breeze.linalg.SparseVector[Double] = SparseVector((513,6.242842104709322), (1858,6.0016800478924335), (2316,12.076095384126617), (2325,3.123284481042985), (4594,4.050680829329649), (5212,58.07524033451476), (5381,4.309153177127207), (6369,2.610052117246429), (7617,48.79675397375542), (9616,2.241310842092959), (11065,7.724446645633537), (11104,5.765172669367298), (13396,5.326236474443527), (14385,4.271289525040671), (16426,4.9394354033951995), (18327,4.271289525040671), (19208,2.327397810375992), (20039,5.572684442374076), (20509,22.6085010134761), (20832,5.293551900402247), (22552,6.563590778286442), (23126,3.735462599069263), (23893,7.154962007262976), (24386,4.086860485907152), (24980,3.9006783905444626), (25551,10.607950447836485), (26044,6.289362120344215), (26214,2.9847455...\ncosineSim: Double = 0.08413245056734778\n0.08413245056734778\r\n"}},{"config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1483713266189_-1827011536","id":"20170106-233426_323110564","dateCreated":"2017-01-06T23:34:26+0900","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:3327","text":"// compare to comp.graphics topic\r\nval graphicsText = rdd.filter { case (file, text) => file.contains(\"comp.graphics\") }\r\nval graphicsTF = graphicsText.mapValues(doc => hashingTF.transform(tokenize(doc)))\r\nval graphicsTfIdf = idf.transform(graphicsTF.map(_._2))\r\nval graphics = graphicsTfIdf.sample(true, 0.1, 42).first.asInstanceOf[SV]\r\nval breezeGraphics = new SparseVector(graphics.indices, graphics.values, graphics.size)\r\nval cosineSim2 = breeze1.dot(breezeGraphics) / (norm(breeze1) * norm(breezeGraphics))\r\n\r\nprintln(cosineSim2)","dateUpdated":"2017-01-07T01:11:25+0900","dateFinished":"2017-01-07T01:11:37+0900","dateStarted":"2017-01-07T01:11:25+0900","result":{"code":"SUCCESS","type":"TEXT","msg":"\ngraphicsText: org.apache.spark.rdd.RDD[(String, String)] = MapPartitionsRDD[980] at filter at <console>:53\n\ngraphicsTF: org.apache.spark.rdd.RDD[(String, org.apache.spark.mllib.linalg.Vector)] = MapPartitionsRDD[981] at mapValues at <console>:74\n\ngraphicsTfIdf: org.apache.spark.rdd.RDD[org.apache.spark.mllib.linalg.Vector] = MapPartitionsRDD[983] at mapPartitions at IDF.scala:178\ngraphics: org.apache.spark.mllib.linalg.SparseVector = (262144,[5455,9103,12781,14156,29945,35959,43377,45145,58162,65531,80287,81417,81566,86960,102451,107257,107299,120642,125372,132778,138193,138677,138895,139561,140390,140532,147765,148967,151589,162813,163197,166629,167918,176359,181584,190355,191422,193347,193924,194478,200749,206904,221047,230921,231726,232076,239859,242109,260935],[5.914315220338022,3.2585385269789535,4.903067759224324,8.235272269399529,1.6340421506706517,3.9448128282511368,5.363592644515516,5.863934722680905,4.346794836923474,4.271289525040671,10.546883095042437,15.448893291267074,0.923831242209304,6.935989285269267,3.1747891695757047,4.4896974716090465,3.5706571577955293,6.561295835827856,1.909609337562069,2.870855101146968,1.6827643823649379,0.003275353700510...breezeGraphics: breeze.linalg.SparseVector[Double] = SparseVector((5455,5.914315220338022), (9103,3.2585385269789535), (12781,4.903067759224324), (14156,8.235272269399529), (29945,1.6340421506706517), (35959,3.9448128282511368), (43377,5.363592644515516), (45145,5.863934722680905), (58162,4.346794836923474), (65531,4.271289525040671), (80287,10.546883095042437), (81417,15.448893291267074), (81566,0.923831242209304), (86960,6.935989285269267), (102451,3.1747891695757047), (107257,4.4896974716090465), (107299,3.5706571577955293), (120642,6.561295835827856), (125372,1.909609337562069), (132778,2.870855101146968), (138193,1.6827643823649379), (138677,0.003275353700510253), (138895,3.0149164443212033), (139561,8.235272269399529), (140390,1.1476985638415549), (140532,0.04030658752139948), (14...\ncosineSim2: Double = 0.01180251153446701\n0.01180251153446701\r\n"}},{"config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1483713264913_-693941349","id":"20170106-233424_942232819","dateCreated":"2017-01-06T23:34:24+0900","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:3257","text":"// compare to sport.baseball topic\r\nval baseballText = rdd.filter { case (file, text) => file.contains(\"baseball\") }\r\nval baseballTF = baseballText.mapValues(doc => hashingTF.transform(tokenize(doc)))\r\nval baseballTfIdf = idf.transform(baseballTF.map(_._2))\r\nval baseball = baseballTfIdf.sample(true, 0.1, 42).first.asInstanceOf[SV]\r\nval breezeBaseball = new SparseVector(baseball.indices, baseball.values, baseball.size)\r\nval cosineSim3 = breeze1.dot(breezeBaseball) / (norm(breeze1) * norm(breezeBaseball))\r\n\r\nprintln(cosineSim3)","dateUpdated":"2017-01-07T01:12:13+0900","dateFinished":"2017-01-07T01:13:44+0900","dateStarted":"2017-01-07T01:12:13+0900","result":{"code":"SUCCESS","type":"TEXT","msg":"\nbaseballText: org.apache.spark.rdd.RDD[(String, String)] = MapPartitionsRDD[985] at filter at <console>:53\n\nbaseballTF: org.apache.spark.rdd.RDD[(String, org.apache.spark.mllib.linalg.Vector)] = MapPartitionsRDD[986] at mapValues at <console>:74\n\nbaseballTfIdf: org.apache.spark.rdd.RDD[org.apache.spark.mllib.linalg.Vector] = MapPartitionsRDD[988] at mapPartitions at IDF.scala:178\nbaseball: org.apache.spark.mllib.linalg.SparseVector = (262144,[6226,6781,9137,11271,12336,22290,23893,27888,28885,29945,30006,37280,37470,40455,45453,49185,49913,50167,53778,55039,58916,59853,60349,62425,66980,76764,83926,84506,87478,88850,96840,99736,102787,104781,105627,106484,107299,110743,112115,113764,125152,133002,135560,138677,140532,140784,148604,150494,155249,157236,162813,163197,163284,167222,167918,175251,175605,181350,186925,188424,189170,189506,193924,195871,200834,203541,204282,205325,206230,207937,217856,221022,221315,224751,233514,235164,239365,241501,242101,245045,246349,249828,252801,257338,259626,260935,261512,261622],[11.557072993156448,4.451082635481267,3.630102083411437,4.891233301577321,3.6201517525582685,7.2544430163878015,2.3849873357543254,5.129191938676672,3....breezeBaseball: breeze.linalg.SparseVector[Double] = SparseVector((6226,11.557072993156448), (6781,4.451082635481267), (9137,3.630102083411437), (11271,4.891233301577321), (12336,3.6201517525582685), (22290,7.2544430163878015), (23893,2.3849873357543254), (27888,5.129191938676672), (28885,3.949389495278549), (29945,1.6340421506706517), (30006,2.696626526783181), (37280,6.289362120344215), (37470,0.9965359935704624), (40455,3.7134836923504877), (45453,5.696298398341252), (49185,2.183967721935529), (49913,5.029819464863468), (50167,13.251668713930856), (53778,3.6037847750940633), (55039,1.2334196670382755), (58916,6.038047692063309), (59853,1.9259602355080387), (60349,10.979832322136474), (62425,0.3723902347580378), (66980,1.8261944802477341), (76764,1.7430324343790569), (83926,2.71514557...\ncosineSim3: Double = 0.013523590269357991\n0.013523590269357991\r\n"}},{"config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1483713389049_674777410","id":"20170106-233629_1760875443","dateCreated":"2017-01-06T23:36:29+0900","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:3677","text":"// === document classification === //\r\nimport org.apache.spark.mllib.regression.LabeledPoint\r\nimport org.apache.spark.mllib.classification.NaiveBayes\r\nimport org.apache.spark.mllib.evaluation.MulticlassMetrics\r\n\r\nval newsgroupsMap = newsgroups.distinct.collect().zipWithIndex.toMap\r\nval zipped = newsgroups.zip(tfidf)\r\nval train = zipped.map { case (topic, vector) => LabeledPoint(newsgroupsMap(topic), vector) }\r\ntrain.cache\r\nval model = NaiveBayes.train(train, lambda = 0.1)\r\n\r\nval testPath = path + \"\\\\20news-bydate-test\\\\*\"\r\nval testRDD = sc.wholeTextFiles(testPath)\r\nval testLabels = testRDD.map { case (file, text) => \r\n\tval topic = file.split(\"/\").takeRight(2).head\r\n\tnewsgroupsMap(topic)\r\n}\r\nval testTf = testRDD.map { case (file, text) => hashingTF.transform(tokenize(text)) }\r\nval testTfIdf = idf.transform(testTf)\r\nval zippedTest = testLabels.zip(testTfIdf)\r\nval test = zippedTest.map { case (topic, vector) => LabeledPoint(topic, vector) }\r\n\r\nval predictionAndLabel = test.map(p => (model.predict(p.features), p.label))\r\nval accuracy = 1.0 * predictionAndLabel.filter(x => x._1 == x._2).count() / test.count()\r\n\r\nprintln(accuracy)","dateUpdated":"2017-01-07T01:14:11+0900","dateFinished":"2017-01-07T01:34:28+0900","dateStarted":"2017-01-07T01:14:11+0900","result":{"code":"SUCCESS","type":"TEXT","msg":"\nimport org.apache.spark.mllib.regression.LabeledPoint\n\nimport org.apache.spark.mllib.classification.NaiveBayes\n\nimport org.apache.spark.mllib.evaluation.MulticlassMetrics\n\nnewsgroupsMap: scala.collection.immutable.Map[String,Int] = Map(rec.sport.hockey -> 18, sci.space -> 10, comp.graphics -> 2, sci.crypt -> 11, alt.atheism -> 3, sci.med -> 14, comp.windows.x -> 4, soc.religion.christian -> 13, talk.politics.mideast -> 6, misc.forsale -> 9, comp.sys.ibm.pc.hardware -> 12, talk.religion.misc -> 16, comp.sys.mac.hardware -> 17, rec.sport.baseball -> 5, rec.autos -> 7, rec.motorcycles -> 1, talk.politics.guns -> 8, talk.politics.misc -> 15, comp.os.ms-windows.misc -> 19, sci.electronics -> 0)\n\nzipped: org.apache.spark.rdd.RDD[(String, org.apache.spark.mllib.linalg.Vector)] = ZippedPartitionsRDD2[993] at zip at <console>:85\n\ntrain: org.apache.spark.rdd.RDD[org.apache.spark.mllib.regression.LabeledPoint] = MapPartitionsRDD[994] at map at <console>:89\n\nres156: train.type = MapPartitionsRDD[994] at map at <console>:89\n\nmodel: org.apache.spark.mllib.classification.NaiveBayesModel = org.apache.spark.mllib.classification.NaiveBayesModel@7b4b59fc\n\ntestPath: String = D:\\Project\\Spark\\Machine-Learning-with-Spark\\Data\\20news-bydate\\20news-bydate-test\\*\n\ntestRDD: org.apache.spark.rdd.RDD[(String, String)] = D:\\Project\\Spark\\Machine-Learning-with-Spark\\Data\\20news-bydate\\20news-bydate-test\\* MapPartitionsRDD[998] at wholeTextFiles at <console>:56\n\ntestLabels: org.apache.spark.rdd.RDD[Int] = MapPartitionsRDD[999] at map at <console>:63\n\ntestTf: org.apache.spark.rdd.RDD[org.apache.spark.mllib.linalg.Vector] = MapPartitionsRDD[1000] at map at <console>:79\n\ntestTfIdf: org.apache.spark.rdd.RDD[org.apache.spark.mllib.linalg.Vector] = MapPartitionsRDD[1001] at mapPartitions at IDF.scala:178\n\nzippedTest: org.apache.spark.rdd.RDD[(Int, org.apache.spark.mllib.linalg.Vector)] = ZippedPartitionsRDD2[1002] at zip at <console>:95\n\ntest: org.apache.spark.rdd.RDD[org.apache.spark.mllib.regression.LabeledPoint] = MapPartitionsRDD[1003] at map at <console>:97\n\npredictionAndLabel: org.apache.spark.rdd.RDD[(Double, Double)] = MapPartitionsRDD[1004] at map at <console>:107\n\naccuracy: Double = 0.789830058417419\n0.789830058417419\r\n"}},{"config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1483713388414_1254963427","id":"20170106-233628_1078779545","dateCreated":"2017-01-06T23:36:28+0900","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:3607","text":"val metrics = new MulticlassMetrics(predictionAndLabel)\r\nprintln(metrics.weightedFMeasure)","dateUpdated":"2017-01-07T01:37:14+0900","dateFinished":"2017-01-07T01:46:20+0900","dateStarted":"2017-01-07T01:37:14+0900","result":{"code":"SUCCESS","type":"TEXT","msg":"\nmetrics: org.apache.spark.mllib.evaluation.MulticlassMetrics = org.apache.spark.mllib.evaluation.MulticlassMetrics@6671eba2\n0.7797249298047971\r\n"}},{"config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1483713387312_1677417719","id":"20170106-233627_691459746","dateCreated":"2017-01-06T23:36:27+0900","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:3537","text":"// test on raw token features\r\nval rawTokens = rdd.map { case (file, text) => text.split(\" \") }\r\nval rawTF = rawTokens.map(doc => hashingTF.transform(doc))\r\nval rawTrain = newsgroups.zip(rawTF).map { case (topic, vector) => LabeledPoint(newsgroupsMap(topic), vector) }\r\nval rawModel = NaiveBayes.train(rawTrain, lambda = 0.1)\r\nval rawTestTF = testRDD.map { case (file, text) => hashingTF.transform(text.split(\" \")) }\r\nval rawZippedTest = testLabels.zip(rawTestTF)\r\nval rawTest = rawZippedTest.map { case (topic, vector) => LabeledPoint(topic, vector) }\r\nval rawPredictionAndLabel = rawTest.map(p => (rawModel.predict(p.features), p.label))\r\nval rawAccuracy = 1.0 * rawPredictionAndLabel.filter(x => x._1 == x._2).count() / rawTest.count()\r\nprintln(rawAccuracy)","dateUpdated":"2017-01-07T01:48:20+0900","dateFinished":"2017-01-07T02:01:05+0900","dateStarted":"2017-01-07T01:48:21+0900","result":{"code":"SUCCESS","type":"TEXT","msg":"\nrawTokens: org.apache.spark.rdd.RDD[Array[String]] = MapPartitionsRDD[1014] at map at <console>:58\n\nrawTF: org.apache.spark.rdd.RDD[org.apache.spark.mllib.linalg.Vector] = MapPartitionsRDD[1015] at map at <console>:63\n\nrawTrain: org.apache.spark.rdd.RDD[org.apache.spark.mllib.regression.LabeledPoint] = MapPartitionsRDD[1017] at map at <console>:69\n\nrawModel: org.apache.spark.mllib.classification.NaiveBayesModel = org.apache.spark.mllib.classification.NaiveBayesModel@21d0a3bd\n\nrawTestTF: org.apache.spark.rdd.RDD[org.apache.spark.mllib.linalg.Vector] = MapPartitionsRDD[1020] at map at <console>:65\n\nrawZippedTest: org.apache.spark.rdd.RDD[(Int, org.apache.spark.mllib.linalg.Vector)] = ZippedPartitionsRDD2[1021] at zip at <console>:73\n\nrawTest: org.apache.spark.rdd.RDD[org.apache.spark.mllib.regression.LabeledPoint] = MapPartitionsRDD[1022] at map at <console>:75\n\nrawPredictionAndLabel: org.apache.spark.rdd.RDD[(Double, Double)] = MapPartitionsRDD[1023] at map at <console>:85\n\nrawAccuracy: Double = 0.7632766861391397\n0.7632766861391397\r\n"}},{"config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1483713555628_-810339665","id":"20170106-233915_366602363","dateCreated":"2017-01-06T23:39:15+0900","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:3817","text":"val rawMetrics = new MulticlassMetrics(rawPredictionAndLabel)\r\nprintln(rawMetrics.weightedFMeasure)","dateUpdated":"2017-01-07T02:04:01+0900","dateFinished":"2017-01-07T02:20:00+0900","dateStarted":"2017-01-07T02:04:01+0900","result":{"code":"SUCCESS","type":"TEXT","msg":"\nrawMetrics: org.apache.spark.mllib.evaluation.MulticlassMetrics = org.apache.spark.mllib.evaluation.MulticlassMetrics@ada53e8\n0.7636832042668226\r\n"}},{"config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1483713554686_-434055240","id":"20170106-233914_271427115","dateCreated":"2017-01-06T23:39:14+0900","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:3747","text":"// === Word2Vec === /\r\nimport org.apache.spark.mllib.feature.Word2Vec\r\nval word2vec = new Word2Vec()\r\nword2vec.setSeed(42) // we do this to generate the same results each time\r\n\r\nval word2vecModel = word2vec.fit(tokens)\r\n\r\n// evaluate a few words\r\nword2vecModel.findSynonyms(\"hockey\", 20).foreach(println)\r\nword2vecModel.findSynonyms(\"legislation\", 20).foreach(println)\r\n","dateUpdated":"2017-01-07T02:29:35+0900","dateFinished":"2017-01-07T02:36:23+0900","dateStarted":"2017-01-07T02:29:35+0900","result":{"code":"SUCCESS","type":"TEXT","msg":"\nimport org.apache.spark.mllib.feature.Word2Vec\n\nword2vec: org.apache.spark.mllib.feature.Word2Vec = org.apache.spark.mllib.feature.Word2Vec@486acccf\n\nres167: word2vec.type = org.apache.spark.mllib.feature.Word2Vec@486acccf\n\nword2vecModel: org.apache.spark.mllib.feature.Word2VecModel = org.apache.spark.mllib.feature.Word2VecModel@4da7b6d2\n(glens,0.6368746359693075)\r\n(ecac,0.6297782143554729)\r\n(ahl,0.5970988408281629)\r\n(sport,0.5887983815663405)\r\n(woofers,0.5805908251309851)\r\n(commissioner,0.5699180435103647)\r\n(hispanic,0.5683752950201805)\r\n(roster,0.55659910919097)\r\n(ncaa,0.5517767678069799)\r\n(champs,0.551741628081963)\r\n(golf,0.547406076440631)\r\n(surprises,0.5441397428950324)\r\n(rec,0.5426220400876366)\r\n(tournament,0.5333161926930022)\r\n(pool,0.5308288540509536)\r\n(collegiate,0.5257797937111887)\r\n(awards,0.5217340806899551)\r\n(boxscores,0.521280855175266)\r\n(playoff,0.5211550022582268)\r\n(homeruns,0.516936860525219)\r\n(accommodates,0.747511518104625)\r\n(agency,0.7208870089125291)\r\n(briefed,0.7149952204427447)\r\n(amended,0.713608013327178)\r\n(policies,0.7109563030696658)\r\n(advocate,0.7086776500330177)\r\n(rkba,0.6994777017389908)\r\n(journals,0.6887115048512787)\r\n(aclu,0.6879825411746541)\r\n(amendments,0.678153857296892)\r\n(kates,0.6761922713518644)\r\n(papers,0.6741937231119078)\r\n(procurement,0.6719598853731364)\r\n(senate,0.6697471657526155)\r\n(layman,0.6693318185696087)\r\n(privacy,0.665251621440007)\r\n(possession,0.6631945926124474)\r\n(officials,0.6614395312784452)\r\n(cooperation,0.6596557864246114)\r\n(director,0.6594966287648484)\r\n"}},{"config":{"colWidth":11,"graph":{"mode":"table","height":86,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1483712684220_544155420","id":"20170106-232444_1630135033","dateCreated":"2017-01-06T23:24:44+0900","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:1997","text":"","dateUpdated":"2017-01-07T02:13:44+0900","dateFinished":"2017-01-06T23:45:35+0900","dateStarted":"2017-01-06T23:45:35+0900","result":{"code":"SUCCESS","type":"TEXT","msg":""}}],"name":"Chapter 09","id":"2C611FAYJ","angularObjects":{"2C47MGX9B:shared_process":[],"2C22X7YME:shared_process":[],"2C3K6RKJN:shared_process":[],"2C2EWZ9TA:shared_process":[],"2C2JMDYZ3:shared_process":[],"2C1S848VZ:shared_process":[],"2C2QVVB9Q:shared_process":[],"2C43GNJ9W:shared_process":[],"2C12D5W9R:shared_process":[],"2C1T2UZ3P:shared_process":[],"2C3G51W1E:shared_process":[],"2C36955YP:shared_process":[],"2BZTACRZS:shared_process":[],"2C4AVWZ7X:shared_process":[],"2C3MT2CTG:shared_process":[],"2C1T89CKC:shared_process":[],"2C33Z58NN:shared_process":[],"2C29H1CDW:shared_process":[]},"config":{"looknfeel":"default"},"info":{}}